{"metadata":{"orig_nbformat":4,"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy\n!pip install scipy\n!pip install seaborn\n!pip install pandas\n!pip install matplotlib\n!pip install sklearn\n!pip install pymatgen\n!pip install tensorflow","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.21.4)\nRequirement already satisfied: scipy in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.7.3)\nRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scipy) (1.21.4)\nRequirement already satisfied: seaborn in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.11.2)\nRequirement already satisfied: matplotlib>=2.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (3.5.0)\nRequirement already satisfied: pandas>=0.23 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (1.3.4)\nRequirement already satisfied: scipy>=1.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (1.7.3)\nRequirement already satisfied: numpy>=1.15 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (1.21.4)\nRequirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\nRequirement already satisfied: pillow>=6.2.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\nRequirement already satisfied: setuptools-scm>=4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (6.3.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (3.0.6)\nRequirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (4.28.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\nRequirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (21.3)\nRequirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2021.3)\nRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\nRequirement already satisfied: tomli>=1.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (1.2.2)\nRequirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (59.1.1)\nRequirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.3.4)\nRequirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (1.21.4)\nRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\nRequirement already satisfied: matplotlib in /srv/conda/envs/notebook/lib/python3.7/site-packages (3.5.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: pillow>=6.2.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (8.4.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (3.0.6)\nRequirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (4.28.3)\nRequirement already satisfied: numpy>=1.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (1.21.4)\nRequirement already satisfied: setuptools-scm>=4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (6.3.2)\nRequirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: tomli>=1.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\nRequirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib) (59.1.1)\nRequirement already satisfied: sklearn in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /srv/conda/envs/notebook/lib/python3.7/site-packages (from sklearn) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->sklearn) (3.0.0)\nRequirement already satisfied: joblib>=0.11 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.1.0)\nRequirement already satisfied: scipy>=1.1.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.7.3)\nRequirement already satisfied: numpy>=1.14.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.21.4)\nRequirement already satisfied: pymatgen in /srv/conda/envs/notebook/lib/python3.7/site-packages (2022.0.16)\nRequirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (2.26.0)\nRequirement already satisfied: tabulate in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (0.8.9)\nRequirement already satisfied: uncertainties>=3.1.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (3.1.6)\nRequirement already satisfied: ruamel.yaml>=0.15.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (0.17.17)\nRequirement already satisfied: sympy in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (1.9)\nRequirement already satisfied: monty>=3.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (2021.12.1)\nRequirement already satisfied: plotly>=4.5.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (5.4.0)\nRequirement already satisfied: networkx>=2.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (2.6.3)\nRequirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (1.3.4)\nRequirement already satisfied: palettable>=3.1.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (3.3.0)\nRequirement already satisfied: matplotlib>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (3.5.0)\nRequirement already satisfied: numpy>=1.20.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (1.21.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (4.0.0)\nRequirement already satisfied: spglib>=1.9.9.44 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (1.16.2)\nRequirement already satisfied: scipy>=1.5.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pymatgen) (1.7.3)\nRequirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.5->pymatgen) (4.28.3)\nRequirement already satisfied: pillow>=6.2.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.5->pymatgen) (8.4.0)\nRequirement already satisfied: setuptools-scm>=4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.5->pymatgen) (6.3.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.5->pymatgen) (3.0.6)\nRequirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.5->pymatgen) (0.11.0)\nRequirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.5->pymatgen) (21.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.5->pymatgen) (1.3.2)\nRequirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.5->pymatgen) (2.8.2)\nRequirement already satisfied: tenacity>=6.2.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from plotly>=4.5.0->pymatgen) (8.0.1)\nRequirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.7/site-packages (from plotly>=4.5.0->pymatgen) (1.16.0)\nRequirement already satisfied: ruamel.yaml.clib>=0.1.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ruamel.yaml>=0.15.6->pymatgen) (0.2.6)\nRequirement already satisfied: future in /srv/conda/envs/notebook/lib/python3.7/site-packages (from uncertainties>=3.1.4->pymatgen) (0.18.2)\nRequirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas->pymatgen) (2021.3)\nRequirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->pymatgen) (3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->pymatgen) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->pymatgen) (2.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->pymatgen) (2021.10.8)\nRequirement already satisfied: mpmath>=0.19 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from sympy->pymatgen) (1.2.1)\nRequirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib>=1.5->pymatgen) (59.1.1)\nRequirement already satisfied: tomli>=1.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib>=1.5->pymatgen) (1.2.2)\nRequirement already satisfied: tensorflow in /srv/conda/envs/notebook/lib/python3.7/site-packages (2.7.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (4.0.0)\nRequirement already satisfied: h5py>=2.9.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (3.6.0)\nRequirement already satisfied: protobuf>=3.9.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (3.19.1)\nRequirement already satisfied: numpy>=1.14.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.21.4)\nRequirement already satisfied: astunparse>=1.6.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: wheel<1.0,>=0.32.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (2.7.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.42.0)\nRequirement already satisfied: six>=1.12.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (0.22.0)\nRequirement already satisfied: gast<0.5.0,>=0.2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (2.0)\nRequirement already satisfied: termcolor>=1.1.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: wrapt>=1.11.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.13.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: libclang>=9.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (12.0.0)\nRequirement already satisfied: keras<2.8,>=2.7.0rc0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (2.7.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: tensorboard~=2.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (2.7.0)\nRequirement already satisfied: absl-py>=0.4.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.0.0)\nRequirement already satisfied: cached-property in /srv/conda/envs/notebook/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\nRequirement already satisfied: werkzeug>=0.11.15 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\nRequirement already satisfied: markdown>=2.6.8 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\nRequirement already satisfied: setuptools>=41.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (59.1.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\nRequirement already satisfied: importlib-metadata>=4.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.0)\nRequirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n","output_type":"stream"}],"id":"95e9dc2f-16d5-4680-b4f7-fad3f1268ae5"},{"cell_type":"code","source":"# Importing Libraries\nimport numpy as np\nimport scipy as sp\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_predict, cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier, \\\n    GradientBoostingClassifier, GradientBoostingRegressor, \\\n    RandomForestClassifier, RandomForestRegressor\nfrom scipy import linalg\nfrom sklearn.discriminant_analysis import (LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA)\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom pymatgen.core import Element, Composition, periodic_table\nfrom functools import partial\nfrom pymatgen.ext.matproj import MPRester\nmpr = MPRester(\"241iWwhTEOaNmC6V\")\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\nfrom sklearn import svm, datasets\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nimport tensorflow.keras.layers as layers\nimport tensorflow as tf\nfrom pandas.plotting import scatter_matrix\n","metadata":{"trusted":true},"execution_count":53,"outputs":[],"id":"e39dac21-8a87-48df-aa6a-799fd067c1af"},{"cell_type":"code","source":"#loading the testing and training data into the file to be manipulated in several forms\n\ntrain = pd.read_csv(\"train.csv\",index_col=False)\ntest = pd.read_csv(\"test.csv\",index_col=False)\n\n","metadata":{"trusted":true},"execution_count":3,"outputs":[],"id":"1b6cbe1e-8089-480e-8f59-560e045057a6"},{"cell_type":"code","source":"#Using pymatgen and the material ID we can query some of the data in our training set that we will use AND we will store this in a dataframe\n\nbase_data = mpr.query(criteria={\"task_id\": {\"$in\":train[\"material_id\"].to_list()}}, properties=[\"material_id\",\"energy\",\n        \"energy_per_atom\",\n        \"volume\",\n        \"formation_energy_per_atom\",\n        \"nsites\",\n        \"pretty_formula\",                                                                                  \n        \"nelements\",\n        \"density\",  \"band_gap\"])\nbase_data_DF = pd.DataFrame(base_data)\n\n","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"0 of 5619 done 0.0%\n500 of 5619 done 8.9%\n1000 of 5619 done 17.8%\n1500 of 5619 done 26.7%\n2000 of 5619 done 35.6%\n2500 of 5619 done 44.5%\n3000 of 5619 done 53.4%\n3500 of 5619 done 62.3%\n4000 of 5619 done 71.2%\n4500 of 5619 done 80.1%\n5000 of 5619 done 89.0%\n5500 of 5619 done 97.9%\n5619 of 5619 done 100.0%\n","output_type":"stream"}],"id":"ebe0b7ab-1efc-4581-bfcd-555e8a33e724"},{"cell_type":"code","source":"#for the training data we will remove noble gases. Later on we will have to apply fixes to our code because the test set includes Xe \n\n\n#Making list of possible noble gases \nnobles = [\"He\",\"Ne\", \"Ar\", \"Kr\", \"Xe\", \"Rn\", \"Og\"]\nNoNobles_base_data_DF = base_data_DF\n\n#Iterating through data and using pandas drop function to filter out materials containing noble gas elements \nfor i in nobles:\n    NoNobles_base_data_DF = NoNobles_base_data_DF.drop(NoNobles_base_data_DF[NoNobles_base_data_DF['pretty_formula'].str.contains(i)].index)\n    \n    ","metadata":{"trusted":true},"execution_count":6,"outputs":[],"id":"2b5483cf-286e-4871-97fb-eb91ed7a98e3"},{"cell_type":"code","source":"#this isn't the most efficient way to do this but why fix somthing that isnt technically broken\n#I need to make an element properties dataframe similar to lab 2. How i did it in lab 2 was to get a list of unique elements in the NoNobles_base_data_DF and then making a dataframe that includes the data of each element\n\n\nlistA = [a for a in NoNobles_base_data_DF[\"pretty_formula\"]]\nlistB = [Composition(a) for a in listA]\nlistC = [a.elements for a in listB]\n\neditC = [item for sublist in listC for item in sublist]\nunique_editC = set(editC)\nunique_editC\n\nUL_editC = [a for a in unique_editC]\nindiv_ELproperties_train = [a.data for a in UL_editC]\n\npeel = set(UL_editC)\nsy_editC = [a.symbol for a in UL_editC]\nsy_editC\n\nindiv_ELproperties_train_DF = pd.DataFrame(indiv_ELproperties_train, index=sy_editC)\n\nindiv_ELproperties_train_DF.head()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"634834ea-2288-4c7d-9244-109c55c1cf50"},{"cell_type":"code","source":"#Off top there are some properties that I don't want to use, either because there is significant lack of data for them, they are mostly words and not numbers or they are ranges, or they seem to be repeated\n#there will be several droplists i will try to make this more ordered by numbering them all\n\ndroplist_1 = ['Ionic radii',\n    'Ionic radii hs', \n     'Ionic radii ls',\n     'iupac_ordering', \n     'IUPAC ordering', \n     'NMR Quadrupole Moment', \n     'Reflectivity',\n     'Refractive index', \n     'Rigidity modulus', \n     'Shannon radii',\n     'Superconduction temperature',\n     'Mendeleev no',       \n     'Mineral hardness',\n     'Molar volume',\n     'Name',\n     'Oxidation states',\n     'ICSD oxidation states',\n     'Brinell hardness',\n     'Atomic orbitals', \n     'Coefficient of linear thermal expansion',\n     'Atomic orbitals',\n     'Electronic structure',\n     'Electrical resistivity',\n     'Ground level'\n           ]\n\n\nindiv_ELproperties_train_DF = indiv_ELproperties_train_DF.drop(columns=droplist_1)\n\n\nindiv_ELproperties_train_DF.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"5957c8f6-2393-49cf-8e0e-e491a9308b35"},{"cell_type":"markdown","source":"So initially we only queried and used the data available on pymatgen without building any features like we did in lab 2 that model performance wasn't good. it was my first attempt and it had a value of 173 when I submitted it to kaggle. We talked to the TA and he said to build the features out. Now the .data command took us forever to find. I don't know why. But once we found that and had the values at least we could start to do data cleaning of the data we had enough of. But I did want to say this part took us SO SO long. It was honestly very frustrating and in the future i think it might be worth it to provide more examples of the data cleaning so that we can focus more on choosing features and models and not data cleaning.","metadata":{},"id":"1c899a6a-ce13-4ef1-9266-68405206dbb1"},{"cell_type":"code","source":"#Data cleaning lines. These should all work. But you can't run them twice without error. You are saving the new clean data into the dataframe so it wont be able to find anything since it is very column specific and once ran once\n##there is nothing to fix. that being said the coerce to apply numeric is in a different box because i dont want to risk it making them numeric before i do a bunch of string operations. \n\nindiv_ELproperties_train_DF['Boiling point'] = [(a.replace('K', '', 1)) for a in indiv_ELproperties_train_DF['Boiling point']]\nindiv_ELproperties_train_DF['Bulk modulus'] = indiv_ELproperties_train_DF[\"Bulk modulus\"].str.replace(\"GPa\", \"\")\nindiv_ELproperties_train_DF['Critical temperature'] = indiv_ELproperties_train_DF[\"Critical temperature\"].str.replace(\"K\", \"\")\nindiv_ELproperties_train_DF['Density of solid'] = indiv_ELproperties_train_DF['Density of solid'].str.replace(\"no data\", \"NaN\")\nindiv_ELproperties_train_DF['Density of solid'] = indiv_ELproperties_train_DF[\"Density of solid\"].str.replace(\"kg m<sup>-3</sup>\", \"\")\nindiv_ELproperties_train_DF['Liquid range'] = [(a.replace('K', '', 1)) for a in indiv_ELproperties_train_DF['Liquid range']]\nindiv_ELproperties_train_DF['Poissons ratio'] = [(a.replace('no data', 'NaN', 1)) for a in indiv_ELproperties_train_DF['Poissons ratio']]\nindiv_ELproperties_train_DF['Poissons ratio'] = indiv_ELproperties_train_DF['Poissons ratio'].str.replace(\"no data\", \"\").astype(float)\nindiv_ELproperties_train_DF['Thermal conductivity'] = [float(a.replace('W m<sup>-1</sup> K<sup>-1</sup>', \"\", 1)) for a in indiv_ELproperties_train_DF['Thermal conductivity']]\nindiv_ELproperties_train_DF['Velocity of sound'] = indiv_ELproperties_train_DF['Velocity of sound'].str.replace(\"no data\",\"NaN\")\nindiv_ELproperties_train_DF['Velocity of sound'] = [(a.replace('m s<sup>-1</sup>', '', 1)) for a in indiv_ELproperties_train_DF['Velocity of sound']]\nindiv_ELproperties_train_DF['Vickers hardness'] = indiv_ELproperties_train_DF['Vickers hardness'].str.replace(\"no data\", \"NaN\")\nindiv_ELproperties_train_DF['Vickers hardness'] = [(a.replace('MN m<sup>-2</sup>', '', 1)) for a in indiv_ELproperties_train_DF['Vickers hardness']]\nindiv_ELproperties_train_DF['Youngs modulus'] = indiv_ELproperties_train_DF['Youngs modulus'].str.replace(\"no data\", \"NaN\")\nindiv_ELproperties_train_DF['Youngs modulus'] = [(a.replace('GPa', '', 1)) for a in indiv_ELproperties_train_DF['Youngs modulus']]\nindiv_ELproperties_train_DF['Bulk modulus'] = [(a.replace('no data', 'NaN', 1)) for a in indiv_ELproperties_train_DF['Bulk modulus']]\nindiv_ELproperties_train_DF['Bulk modulus'] = [(a.replace('liquid', '', 1)) for a in indiv_ELproperties_train_DF['Bulk modulus']]\nindiv_ELproperties_train_DF['Bulk modulus'] = indiv_ELproperties_train_DF['Bulk modulus'].str.replace(r\"\\(.*\\)\",\"\",  regex=True).astype(float)\nindiv_ELproperties_train_DF['Melting point'] = indiv_ELproperties_train_DF['Melting point'].str.replace(\"K\", \"\")\nindiv_ELproperties_train_DF['Melting point'] = indiv_ELproperties_train_DF['Melting point'].str.replace(\"white P\", \"\")\nindiv_ELproperties_train_DF['Melting point'] = indiv_ELproperties_train_DF['Melting point'].str.replace(r\"\\(.*\\)\",\"\",  regex=True).astype(float)\nindiv_ELproperties_train_DF['Metallic radius'] = indiv_ELproperties_train_DF['Metallic radius'].astype(str)\nindiv_ELproperties_train_DF['Metallic radius'] = [(a.replace('no data', 'NaN', 1)) for a in indiv_ELproperties_train_DF['Metallic radius']]\nindiv_ELproperties_train_DF['Metallic radius'] = indiv_ELproperties_train_DF['Metallic radius'].astype(float)\nindiv_ELproperties_train_DF['Common oxidation states'] = [len(a) for a in indiv_ELproperties_train_DF['Common oxidation states']]\nindiv_ELproperties_train_DF['First Ionization Energy'] = [a[0] for a in indiv_ELproperties_train_DF['Ionization energies']]\n\nindiv_ELproperties_train_DF = indiv_ELproperties_train_DF.drop(\"Ionization energies\", axis=1)\n\nindiv_ELproperties_train_DF['Critical temperature'] = [(a.replace('no data', 'NaN', 1)) for a in indiv_ELproperties_train_DF['Critical temperature']]\n","metadata":{"trusted":true},"execution_count":9,"outputs":[],"id":"f274021c-8d5c-4bc2-9f8f-11860ee7fb70"},{"cell_type":"code","source":"indiv_ELproperties_train_DF = indiv_ELproperties_train_DF.apply(pd.to_numeric, errors='coerce')","metadata":{"trusted":true},"execution_count":10,"outputs":[],"id":"7b7c5859-18b0-45be-a85a-193fb30431c8"},{"cell_type":"code","source":"#We need to compute the mean values of each column so that way we can place the means of each column in the spaces where we previously made sure there was NAN\n\n#means\nmean_col_vals = dict(indiv_ELproperties_train_DF.mean())\nmean_col_vals\n\n\n# Iterating through variable with averages to replace the NaN values in element_data\nfor key, value in mean_col_vals.items():\n    indiv_ELproperties_train_DF.loc[indiv_ELproperties_train_DF[key].isnull(),key] = value\n\n","metadata":{"trusted":true},"execution_count":11,"outputs":[],"id":"0ba4ac40-eae7-452f-8e7a-fe0ee5ac981c"},{"cell_type":"code","source":"#We talked with the TA about extensive vs intensive properties and we needed to remove volume and energy as a result. though we could keep volume/atom. however we would have to build that first. as it is just easier to build\n##that once we cleaned the other data. we did that here\n\n#NoNobles_base_data_DF\n\n\n\nNoNobles_basedata_DF_wcomp = NoNobles_base_data_DF\nNoNobles_basedata_DF_wcomp['Composition'] = [Composition(c) for c in NoNobles_basedata_DF_wcomp[\"pretty_formula\"]]\nNoNobles_basedata_DF_wcomp['num_atoms'] = [c.num_atoms for c in NoNobles_basedata_DF_wcomp['Composition']]\nNoNobles_basedata_DF_wcomp['volume_per_atom'] = NoNobles_basedata_DF_wcomp['volume']/NoNobles_basedata_DF_wcomp['num_atoms']\n\n\n\nNoNobles_basedata_DF_wcomp\n#this should be a dataframe of all the MPIDS with the relevant compositions which is necessary because we are about to start making features for the indiv_ELproperties_train_DF\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"0b38d74d-422a-471e-9ad9-e4e537a584d6"},{"cell_type":"code","source":"#this was the best way i figured out to make the additional properties. this is how i did it in lab 2. radius mean function was removed beceause it is never added to a dataframe and is just a tester to make sure they work\n\n\nindiv_ELproperties_train_DF_dict = indiv_ELproperties_train_DF.to_dict()\n\n#my functions\ndef propertymean(property, composition):\n    sumofproperty = 0\n    totalnumatoms = 0\n    for element, number in composition.items():\n        sumofproperty += (number*indiv_ELproperties_train_DF_dict[property][str(element)])\n        totalnumatoms += number\n    return sumofproperty/totalnumatoms\n\ndef maxofproperty(property, composition):\n    propmax = None\n    for element, number in composition.items():\n        propertyvalue = indiv_ELproperties_train_DF_dict[property][str(element)]\n        if propmax:\n            propmax = propertyvalue if propertyvalue > propmax else propmax\n        else:\n            propmax = propertyvalue\n    return propmax\n\ndef minofproperty(property, composition):\n    propmin = None\n    for element, number in composition.items():\n        propertyvalue = indiv_ELproperties_train_DF_dict[property][str(element)]\n        if propmin:\n            propmin = propertyvalue if propertyvalue < propmin else propmin\n        else:\n            propmin = propertyvalue\n    return propmin\n\n\n\n#assigning the values of those functions to a dataframe\n\navg_properties_df = pd.DataFrame()\n\nfor property in indiv_ELproperties_train_DF.columns:\n    individualpropertymean = partial(propertymean, property)\n    averages = NoNobles_basedata_DF_wcomp['Composition'].apply(individualpropertymean)\n    avg_properties_df[(\"average_\" + property)] = averages\n    \navg_properties_df.head()\nprint(\"Average properties Dimension: \", avg_properties_df.shape)\n\nmax_properties = pd.DataFrame()\n\nfor property in indiv_ELproperties_train_DF.columns:\n    individualpropertymax = partial(maxofproperty, property)\n    max = NoNobles_basedata_DF_wcomp['Composition'].apply(individualpropertymax)\n    max_properties[(\"max_\" + property)] = max\n    \nmin_properties = pd.DataFrame()\n\nfor property in indiv_ELproperties_train_DF.columns:\n    individualpropertymin = partial(minofproperty, property)\n    min = NoNobles_basedata_DF_wcomp['Composition'].apply(individualpropertymin)\n    min_properties[(\"min_\" + property)] = min\n","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Average properties Dimension:  (5614, 21)\n","output_type":"stream"}],"id":"ca96c662-b350-409e-a961-0f1e204dbd3d"},{"cell_type":"code","source":"#Now we need to take all theses dataframes we have made with the min/max/average properties and put them in a single matrix that the models will be performed on\n\n\nALL_Features_Matrix =  pd.concat([NoNobles_basedata_DF_wcomp, avg_properties_df, min_properties, max_properties], axis=1)\n\n#ALL_Features_Matrix.columns\n\n\n#this is the second droplist: this one is to get rid of some features that we needed before to create new features list, but that we cant use because we couldnt clean properly or we intensive properties\ndroplist_2 = ['volume','energy', 'pretty_formula', 'Composition', 'average_Common oxidation states', 'min_Common oxidation states','max_Common oxidation states']\n\n\nmodel_matrix_1 = ALL_Features_Matrix.drop(columns=droplist_2)\nmodel_matrix_1 \n#model_matrix_1 is the feature matrix for the training data that we will later split\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"9fab2f8a-a4de-48d7-87c3-68e829a41ef0"},{"cell_type":"code","source":"#We removed the noble gases from the feature matrix. so we have to make sure that the part of the training set that is just MPIDS and dielectric polytotals has those removed as well\n#While typing this i thought ... I removed noble gases from my training set. will that matter if one is included in my dataset.... something to think about for the next project. \n\n#list of the ids and a dataframe of them\nMPIDs = list(NoNobles_base_data_DF[\"material_id\"])\nMPIDs = pd.DataFrame(MPIDs)\n\n#setting a new dataframe equal to the dataframe that only includes the one in model_matrix_1 which does not include noble gases\n\nNoNobles_training_set = train[train.index.isin(MPIDs.index)] \n\n\n#you have to make the material_id the index because the dataframe operations can't handle strings\nNoNobles_training_set.set_index('material_id')\n\n#have to do the same to the feature matrix // idk why this one needs the inplace true but that took longer to get right that should have.\nmodel_matrix_1.set_index('material_id', inplace=True)\n","metadata":{"trusted":true},"execution_count":15,"outputs":[],"id":"2c3f5877-abc2-486d-a180-1f07ee6c92ad"},{"cell_type":"code","source":"#just in case i want to check what is in the NoNobles_training_set dataframe\n#NoNobles_training_set","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"7e646a89-4770-4ef2-ba61-c30516570bec"},{"cell_type":"code","source":"#just in case i want to check what is in the NoNobles_training_set dataframe\n#model_matrix_1","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"f312458f-ba92-4b98-8504-684fc5682ed3"},{"cell_type":"markdown","source":"Here is where you either run your model or start to do feature selection. I think for simplicity i will do the feature selection here and then do droplists according to different features I would like to drop.\nUltimately I didnt really like any of my models so it really doesn't matter which I choose. I have no clue how people got better than 7ish... which ultimately stephanie and I achieved working together even though i only submitted my 8 on kaggle. so i will have the feature selection first and then just do the splits for each model that i ultimately worked with \n\n\nsome other things we tried that didnt really improve the model accuracy was test size and random state.\n\nWith regards to feature selection.\n\ni tried a heat map (too many properties to see so I would up just printing the correlations to the datafram and looking at them there)\ni tried a scatter_matrix( never fully ran so I assume it was just too much data, so essentially same problem)\n\nI like printing the correlations to a dataframe and coloring those to determine which ones are important(it was brought up that this is low tech and could lead to missing them, but the others seemed like more work than they offered in results. (also additionally I never exactly figured out how to apply two colors to the same map) (you can idnore the ones that are 1 obviously)\n\n","metadata":{},"id":"0d428776-beba-4b59-8522-633f7d0372bc"},{"cell_type":"code","source":"#Getting the correlations\nmodel_matrix_1_corr = model_matrix_1.corr()","metadata":{"trusted":true},"execution_count":16,"outputs":[],"id":"64444e54-0d58-4d46-b27c-9385a9fb16a1"},{"cell_type":"code","source":"#how to make the positive correlatins red\n\ndef color_negative_red(val):\n    color = 'red' if 0.85 < val and val < 1.00 else 'black'\n    return 'color: %s' % color\n\n\nmodel_matrix_1_corr.style.applymap(color_negative_red)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"a5e07e29-d6c4-4858-9f81-3ba5a809e790"},{"cell_type":"code","source":"#how to make the negative correlatins blue\n\ndef color_negative_blue(val):\n    color = 'blue' if -1.00 < val and val < -0.85 else 'black'\n    return 'color: %s' % color\n\nmodel_matrix_1_corr.style.applymap(color_negative_blue)","metadata":{},"execution_count":null,"outputs":[],"id":"f4fc95ed-65f3-4fd0-aea4-b1aa85941d0e"},{"cell_type":"code","source":"#need this block because you need to be able to see which ones are correlated without having to go through the dataframe which is kinda tedius\n\nlookthru = model_matrix_1_corr.columns\n\npos_correlated_ones_dict = {}\n\nfor col in lookthru:\n    var = model_matrix_1_corr[model_matrix_1_corr[col] > 0.85].index.tolist()\n    if col in var:\n        var.remove(col)\n    if var == []:\n        continue\n    pos_correlated_ones_dict[col] = var\nprint(correlated_ones_dict)\n","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"{'average_Atomic mass': ['average_Atomic no'], 'average_Atomic no': ['average_Atomic mass'], 'average_Atomic radius': ['average_Atomic radius calculated', 'average_Van der waals radius'], 'average_Atomic radius calculated': ['average_Atomic radius', 'average_Van der waals radius'], 'average_Boiling point': ['average_Liquid range', 'average_Melting point'], 'average_Liquid range': ['average_Boiling point'], 'average_Melting point': ['average_Boiling point'], 'average_Van der waals radius': ['average_Atomic radius', 'average_Atomic radius calculated'], 'average_X': ['average_First Ionization Energy'], 'average_Electron affinity': ['max_Electron affinity'], 'average_First Ionization Energy': ['average_X'], 'min_Atomic mass': ['min_Atomic no'], 'min_Atomic no': ['min_Atomic mass'], 'min_Atomic radius': ['min_Atomic radius calculated', 'min_Critical temperature', 'min_Van der waals radius'], 'min_Atomic radius calculated': ['min_Atomic radius', 'min_Critical temperature'], 'min_Boiling point': ['min_Liquid range', 'min_Melting point'], 'min_Critical temperature': ['min_Atomic radius', 'min_Atomic radius calculated'], 'min_Liquid range': ['min_Boiling point'], 'min_Melting point': ['min_Boiling point'], 'min_Van der waals radius': ['min_Atomic radius'], 'min_X': ['min_First Ionization Energy'], 'min_First Ionization Energy': ['min_X'], 'max_Atomic mass': ['max_Atomic no'], 'max_Atomic no': ['max_Atomic mass'], 'max_Atomic radius': ['max_Atomic radius calculated', 'max_Van der waals radius', 'max_Metallic radius'], 'max_Atomic radius calculated': ['max_Atomic radius', 'max_Van der waals radius', 'max_Metallic radius'], 'max_Boiling point': ['max_Melting point'], 'max_Melting point': ['max_Boiling point'], 'max_Van der waals radius': ['max_Atomic radius', 'max_Atomic radius calculated', 'max_Metallic radius'], 'max_X': ['max_First Ionization Energy'], 'max_Metallic radius': ['max_Atomic radius', 'max_Atomic radius calculated', 'max_Van der waals radius'], 'max_Electron affinity': ['average_Electron affinity'], 'max_First Ionization Energy': ['max_X']}\n","output_type":"stream"}],"id":"dbc65732-a4f5-4479-a86d-19c1bd30b5c4"},{"cell_type":"markdown","source":"this is the subset of correlated ones you might remove on the positive correlation side\n\n{'average_Atomic mass': ['average_Atomic no'],  \n'average_Atomic radius': ['average_Atomic radius calculated', 'average_Van der waals radius'], , \n'average_Boiling point': ['average_Liquid range', 'average_Melting point'], , \n'average_Melting point': ['average_Boiling point'], \n'average_X': ['average_First Ionization Energy'], \n'average_Electron affinity': ['max_Electron affinity'], \n 'min_Atomic mass': ['min_Atomic no'], \n 'min_Atomic radius': ['min_Atomic radius calculated', 'min_Critical temperature', 'min_Van der waals radius'], \n 'min_Liquid range': ['min_Boiling point'], \n 'min_Melting point': ['min_Boiling point'],\n 'min_Van der waals radius': ['min_Atomic radius'], \n 'min_First Ionization Energy': ['min_X'], \n  'max_Atomic no': ['max_Atomic mass'], \n  'max_Atomic radius calculated': ['max_Atomic radius', 'max_Van der waals radius', 'max_Metallic radius'], \n  \n  \n  this is a subst of the correlated ones you might remove on the negative side\n  \n  average_Atomic radius': ['average_First Ionization Energy']\n  ","metadata":{},"id":"39db36c5-6101-47c5-ab31-e1e6810c1f84"},{"cell_type":"code","source":"#need this block because you need to be able to see which ones are correlated without having to go through the dataframe which is kinda tedius\n\nlookthru2 = model_matrix_1_corr.columns\n\nneg_correlated_ones_dict = {}\n\nfor col in lookthru2:\n    var2 = model_matrix_1_corr[model_matrix_1_corr[col] < -0.85].index.tolist()\n    if col in var2:\n        var2.remove(col)\n    if var2 == []:\n        continue\n    neg_correlated_ones_dict[col] = var2\nprint(neg_correlated_ones_dict)\n","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"{'average_Atomic radius': ['average_First Ionization Energy'], 'average_Atomic radius calculated': ['average_First Ionization Energy'], 'average_First Ionization Energy': ['average_Atomic radius', 'average_Atomic radius calculated'], 'min_Atomic radius calculated': ['max_X', 'max_First Ionization Energy'], 'max_X': ['min_Atomic radius calculated'], 'max_First Ionization Energy': ['min_Atomic radius calculated']}\n","output_type":"stream"}],"id":"b72d5c39-ec9c-413c-8b58-ff45787171fc"},{"cell_type":"code","source":"# I dont really believe you need to run this. But I'll leave it in to show you i tried it. \n# this is the heat map to display the correlations but there are just too many here to sus out and i didnt know a better way than the one above. \n\nfig, ax = plt.subplots()\n## the size of A4 paper\nfig.set_size_inches(14, 10)\nsns.heatmap(model_matrix_1_corr)","metadata":{},"execution_count":null,"outputs":[],"id":"23932d05-feda-4bcf-8e7b-90a88be495a7"},{"cell_type":"code","source":"#This one i tried but i really want to leave this hashtagged because it took soooooo long to run and never completed but again leaving it in so that you know i tried\n\n\n# scatter_matrix(model_matrix_1, figsize=(20,20))\n\n","metadata":{},"execution_count":null,"outputs":[],"id":"c687685d-7361-461f-81f1-3f6619069835"},{"cell_type":"code","source":"#Feature Selection: this is a list of the features that that I will drop from model_matrix_1 based on the feature selection\n\ndroplist_3 = ['max_Van der waals radius','min_Liquid range','max_Atomic radius', 'max_Atomic radius calculated', 'max_Metallic radius']\n\n","metadata":{"trusted":true},"execution_count":19,"outputs":[],"id":"852203a8-b567-424d-b4d0-65a30c66b9ae"},{"cell_type":"markdown","source":"Test Data Querying\n\nFor the sake of saving time. And because we could submit our files to kaggle to check if we are right. Though Ideally we would have kept training the model until we got very close to accurately predicting the Ytest_train data by using the model appropriately. But ultimately we just trained a model. Predicted the data of the actual test set and determined how close we were on kaggle. so there is not a real point to doing the actual model priming here when its not something that we actually did. so we can just query the the test data now. try to predict the values and see how close we get\n","metadata":{},"id":"4428a525-aa54-4fc3-8708-fddbf3730959"},{"cell_type":"code","source":"# Using material IDs provided in training data to get corresponding information from MPD\nbase_data_test = mpr.query(criteria={\"task_id\": {\"$in\":test[\"material_id\"].to_list()}}, properties=[\"material_id\",\"energy\",\n        \"energy_per_atom\",\n        \"volume\",\n        \"formation_energy_per_atom\",\n        \"nsites\",\n        \"pretty_formula\",                                                                                  \n        \"nelements\",\n        \"density\",  \"band_gap\"])\nbase_data_test_DF = pd.DataFrame(base_data_test)\n#display(base_data_test_DF)","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"0 of 1400 done 0.0%\n500 of 1400 done 35.7%\n1000 of 1400 done 71.4%\n1400 of 1400 done 100.0%\n","output_type":"stream"}],"id":"245c3e50-3a49-4a27-9591-439f9fd3bbc4"},{"cell_type":"code","source":"#Here is where for the Training data we removed the Noble Gases but here we will not be doing that so im not sure we actually need to call this anytype of filters\n\n\n\nlistA_X = [a for a in base_data_test_DF[\"pretty_formula\"]]\nlistB_X = [Composition(a) for a in listA_X]\nlistC_X = [a.elements for a in listB_X]\n\neditC_X = [item for sublist in listC_X for item in sublist]\nunique_editC_X = set(editC_X)\nunique_editC_X\n\nUL_editC_X = [a for a in unique_editC_X]\nindiv_ELproperties_test = [a.data for a in UL_editC_X]\n\npeel=set(UL_editC_X)\nsy_editC_X = [a.symbol for a in UL_editC_X]\nsy_editC_X\n\n#pd.set_option('display.max_rows', None)\n\n\nindiv_ELproperties_test_DF = pd.DataFrame(indiv_ELproperties_test, index=sy_editC_X)\n\n#Need droplist4 because you have to get rid of these two columns that exist because xenon is in the test group \ndroplist_4 = droplist_1 + ['Max oxidation state', 'Min oxidation state']\n\n#droplist_4\n\nindiv_ELproperties_test_DF = indiv_ELproperties_test_DF.drop(columns=droplist_4)\n#indiv_ELproperties_test_DF","metadata":{"trusted":true},"execution_count":21,"outputs":[],"id":"1aeec12d-373d-4702-aa5b-3e03a72d012f"},{"cell_type":"code","source":"#Data cleaning of the test data set\n\nindiv_ELproperties_test_DF['Boiling point'] = [(a.replace('K', '', 1)) for a in indiv_ELproperties_test_DF['Boiling point']]\nindiv_ELproperties_test_DF['Bulk modulus'] = indiv_ELproperties_test_DF[\"Bulk modulus\"].str.replace(\"GPa\", \"\")\nindiv_ELproperties_test_DF['Critical temperature'] = indiv_ELproperties_test_DF[\"Critical temperature\"].str.replace(\"K\", \"\")\nindiv_ELproperties_test_DF['Density of solid'] = indiv_ELproperties_test_DF['Density of solid'].str.replace(\"no data\", \"NaN\")\nindiv_ELproperties_test_DF['Density of solid'] = indiv_ELproperties_test_DF[\"Density of solid\"].str.replace(\"kg m<sup>-3</sup>\", \"\")\nindiv_ELproperties_test_DF['Liquid range'] = [(a.replace('K', '', 1)) for a in indiv_ELproperties_test_DF['Liquid range']]\nindiv_ELproperties_test_DF['Poissons ratio'] = [(a.replace('no data', 'NaN', 1)) for a in indiv_ELproperties_test_DF['Poissons ratio']]\nindiv_ELproperties_test_DF['Poissons ratio'] = indiv_ELproperties_test_DF['Poissons ratio'].str.replace(\"no data\", \"\").astype(float)\nindiv_ELproperties_test_DF['Thermal conductivity'] = [float(a.replace('W m<sup>-1</sup> K<sup>-1</sup>', \"\", 1)) for a in indiv_ELproperties_test_DF['Thermal conductivity']]\nindiv_ELproperties_test_DF['Velocity of sound'] = indiv_ELproperties_test_DF['Velocity of sound'].str.replace(\"no data\",\"NaN\")\nindiv_ELproperties_test_DF['Velocity of sound'] = [(a.replace('m s<sup>-1</sup>', '', 1)) for a in indiv_ELproperties_test_DF['Velocity of sound']]\nindiv_ELproperties_test_DF['Vickers hardness'] = indiv_ELproperties_test_DF['Vickers hardness'].str.replace(\"no data\", \"NaN\", 1)\nindiv_ELproperties_test_DF['Vickers hardness'] = [(a.replace('MN m<sup>-2</sup>', '', 1)) for a in indiv_ELproperties_test_DF['Vickers hardness']]\nindiv_ELproperties_test_DF['Youngs modulus'] = indiv_ELproperties_test_DF['Youngs modulus'].str.replace(\"no data\", \"NaN\", 1)\nindiv_ELproperties_test_DF['Youngs modulus'] = [(a.replace('GPa', '', 1)) for a in indiv_ELproperties_test_DF['Youngs modulus']]\nindiv_ELproperties_test_DF['Bulk modulus'] = [(a.replace('no data', 'NaN', 1)) for a in indiv_ELproperties_test_DF['Bulk modulus']]\nindiv_ELproperties_test_DF['Bulk modulus'] = [(a.replace('liquid', '', 1)) for a in indiv_ELproperties_test_DF['Bulk modulus']]\nindiv_ELproperties_test_DF['Bulk modulus'] = indiv_ELproperties_test_DF['Bulk modulus'].str.replace(r\"\\(.*\\)\",\"\",  regex=True).astype(float)\nindiv_ELproperties_test_DF['Melting point'] = indiv_ELproperties_test_DF['Melting point'].str.replace(\"K\", \"\")\nindiv_ELproperties_test_DF['Melting point'] = indiv_ELproperties_test_DF['Melting point'].str.replace(\"white P\", \"\")\nindiv_ELproperties_test_DF['Melting point'] = indiv_ELproperties_test_DF['Melting point'].str.replace(r\"\\(.*\\)\",\"\",  regex=True).astype(float)\nindiv_ELproperties_test_DF['Metallic radius'] = indiv_ELproperties_test_DF['Metallic radius'].astype(str)\nindiv_ELproperties_test_DF['Metallic radius'] = [(a.replace('no data', 'NaN', 1)) for a in indiv_ELproperties_test_DF['Metallic radius']]\nindiv_ELproperties_test_DF['Metallic radius'] = indiv_ELproperties_test_DF['Metallic radius'].astype(float)\n#indiv_ELproperties_test_DF['Common oxidation states'] = [len(a) for a in indiv_ELproperties_test_DF['Common oxidation states']]\nindiv_ELproperties_test_DF['First Ionization Energy'] = [a[0] for a in indiv_ELproperties_test_DF['Ionization energies']]\n\nindiv_ELproperties_test_DF = indiv_ELproperties_test_DF.drop(\"Ionization energies\", axis=1)\n\nindiv_ELproperties_test_DF['Critical temperature'] = [(a.replace('no data', 'NaN', 1)) for a in indiv_ELproperties_test_DF['Critical temperature']]\n\n#this code works but if for any reason there is an error you have to # out certain ones that cannot be run twice\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"ac35f10a-623e-4b72-9e67-dfbc29d5fb3d"},{"cell_type":"code","source":"indiv_ELproperties_test_DF['First Ionization Energy'] = [a[0] for a in indiv_ELproperties_test_DF['Ionization energies']]\n\nindiv_ELproperties_test_DF = indiv_ELproperties_test_DF.drop(\"Ionization energies\", axis=1)\n\nindiv_ELproperties_test_DF['Critical temperature'] = [(a.replace('no data', 'NaN', 1)) for a in indiv_ELproperties_test_DF['Critical temperature']]","metadata":{"trusted":true},"execution_count":33,"outputs":[],"id":"c4b0d48c-f9af-4669-90e6-20f759df1841"},{"cell_type":"code","source":"indiv_ELproperties_test_DF['Atomic radius'] = indiv_ELproperties_test_DF[\"Atomic radius\"].astype(str)","metadata":{"trusted":true},"execution_count":29,"outputs":[],"id":"db7554fc-cbc8-4fe5-a15c-5570214098ee"},{"cell_type":"code","source":"indiv_ELproperties_test_DF['Atomic radius'] = indiv_ELproperties_test_DF[\"Atomic radius\"].str.replace(\"no data\", \"NaN\", 1)","metadata":{"trusted":true},"execution_count":30,"outputs":[],"id":"04124232-1038-4c32-87d6-1f892cf4a1b5"},{"cell_type":"code","source":"indiv_ELproperties_test_DF","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"fffb7f64-4d6b-4b24-85c1-769fce3f2621"},{"cell_type":"code","source":"indiv_ELproperties_test_DF = indiv_ELproperties_test_DF.apply(pd.to_numeric, errors='coerce')","metadata":{"trusted":true},"execution_count":34,"outputs":[],"id":"f47335d6-c2c1-40a4-a4f4-e288d49d097c"},{"cell_type":"code","source":"indiv_ELproperties_test_DF.dtypes","metadata":{"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"Atomic mass                 float64\nAtomic no                     int64\nAtomic radius               float64\nAtomic radius calculated    float64\nBoiling point               float64\nBulk modulus                float64\nCommon oxidation states     float64\nCritical temperature        float64\nDensity of solid            float64\nLiquid range                float64\nMelting point               float64\nPoissons ratio              float64\nThermal conductivity        float64\nVan der waals radius        float64\nVelocity of sound           float64\nVickers hardness            float64\nX                           float64\nYoungs modulus              float64\nMetallic radius             float64\nElectron affinity           float64\nFirst Ionization Energy     float64\ndtype: object"},"metadata":{}}],"id":"e8be0403-e891-4885-9300-ceb7b54b455d"},{"cell_type":"code","source":"#We need to compute the mean values of each column so that way we can place the means of each column in the spaces where we previously made sure there was NAN\n\n#means\nmean_col_vals_test = dict(indiv_ELproperties_test_DF.mean())\nmean_col_vals_test\n\n\n# Iterating through variable with averages to replace the NaN values in element_data\nfor key, value in mean_col_vals_test.items():\n    indiv_ELproperties_test_DF.loc[indiv_ELproperties_test_DF[key].isnull(),key] = value","metadata":{"trusted":true},"execution_count":37,"outputs":[],"id":"48668405-3818-4427-81e0-c6355d8b30c4"},{"cell_type":"code","source":"indiv_ELproperties_test_DF.dtypes","metadata":{"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Atomic mass                 float64\nAtomic no                   float64\nAtomic radius               float64\nAtomic radius calculated    float64\nBoiling point               float64\nBulk modulus                float64\nCommon oxidation states     float64\nCritical temperature        float64\nDensity of solid            float64\nLiquid range                float64\nMelting point               float64\nPoissons ratio              float64\nThermal conductivity        float64\nVan der waals radius        float64\nVelocity of sound           float64\nVickers hardness            float64\nX                           float64\nYoungs modulus              float64\nMetallic radius             float64\nElectron affinity           float64\nFirst Ionization Energy     float64\ndtype: object"},"metadata":{}}],"id":"45c4394a-1566-43a3-8f52-c49b603ef724"},{"cell_type":"code","source":"#Adding some columns that we need \n\nbase_data_test_DF_wcomp = base_data_test_DF\nbase_data_test_DF_wcomp['Composition'] = [Composition(c) for c in base_data_test_DF_wcomp[\"pretty_formula\"]]\nbase_data_test_DF_wcomp['num_atoms'] = [c.num_atoms for c in base_data_test_DF_wcomp['Composition']]\nbase_data_test_DF_wcomp['volume_per_atom'] = base_data_test_DF_wcomp['volume']/base_data_test_DF_wcomp['num_atoms']\n#base_data_test_DF_wcomp","metadata":{"trusted":true},"execution_count":40,"outputs":[],"id":"c35bb7bf-caae-4d0e-8a22-c64c8b0cff3a"},{"cell_type":"code","source":"\n\nindiv_ELproperties_test_DF_dict = indiv_ELproperties_test_DF.to_dict()\n\n\n#my functions\ndef propertymean_X(property, composition):\n    sumofproperty = 0\n    totalnumatoms = 0\n    for element, number in composition.items():\n        sumofproperty += (number*indiv_ELproperties_test_DF_dict[property][str(element)])\n        totalnumatoms += number\n    return sumofproperty/totalnumatoms\n\ndef maxofproperty_X(property, composition):\n    propmax = None\n    for element, number in composition.items():\n        propertyvalue = indiv_ELproperties_test_DF_dict[property][str(element)]\n        if propmax:\n            propmax = propertyvalue if propertyvalue > propmax else propmax\n        else:\n            propmax = propertyvalue\n    return propmax\n\ndef minofproperty_X(property, composition):\n    propmin = None\n    for element, number in composition.items():\n        propertyvalue = indiv_ELproperties_test_DF_dict[property][str(element)]\n        if propmin:\n            propmin = propertyvalue if propertyvalue < propmin else propmin\n        else:\n            propmin = propertyvalue\n    return propmin\n\n\n#assigning the values of those functions to a dataframe\n\navg_properties_df_X = pd.DataFrame()\n\nfor property in indiv_ELproperties_test_DF.columns:\n    individualpropertymean = partial(propertymean_X, property)\n    averages = base_data_test_DF_wcomp['Composition'].apply(individualpropertymean)\n    avg_properties_df_X[(\"average_\" + property)] = averages\n    \navg_properties_df_X.head()\nprint(\"Average properties Dimension: \", avg_properties_df_X.shape)\n\nmax_properties_X = pd.DataFrame()\n\nfor property in indiv_ELproperties_test_DF.columns:\n    individualpropertymax = partial(maxofproperty_X, property)\n    max = base_data_test_DF_wcomp['Composition'].apply(individualpropertymax)\n    max_properties_X[(\"max_\" + property)] = max\n    \nmin_properties_X = pd.DataFrame()\n\nfor property in indiv_ELproperties_test_DF.columns:\n    individualpropertymin = partial(minofproperty_X, property)\n    min = base_data_test_DF_wcomp['Composition'].apply(individualpropertymin)\n    min_properties_X[(\"min_\" + property)] = min\n\n","metadata":{"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Average properties Dimension:  (1400, 21)\n","output_type":"stream"}],"id":"1b8e3978-c401-450f-b1ff-47cda04ce057"},{"cell_type":"code","source":"base_data_test_DF_wcomp","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"b2b90c6f-da59-40ee-bd96-ee2a2b41a44e"},{"cell_type":"code","source":"#model_matrix_2 is our feature space but for the test data\n\nALL_Features_Matrix_test = pd.concat([base_data_test_DF_wcomp, avg_properties_df_X, min_properties_X, max_properties_X], axis=1)\nALL_Features_Matrix_test.columns\n\n#droplist_2 hasnt changed from the one we used for our traindata\nmodel_matrix_2 = ALL_Features_Matrix_test.drop(columns=droplist_2)\n#model_matrix_2","metadata":{"trusted":true},"execution_count":45,"outputs":[],"id":"1db602e0-da54-4799-90fc-7e8a740e76cb"},{"cell_type":"code","source":"#model_matrix_2","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"ff467b3d-eeb3-4b83-aeb0-bde7cc47dec9"},{"cell_type":"code","source":"model_matrix_2.set_index('material_id',inplace=True)","metadata":{"trusted":true},"execution_count":47,"outputs":[],"id":"6dc46cff-8701-4ed6-bb6c-d7e162566b0e"},{"cell_type":"code","source":"# testfornulls = model_matrix_2.isnull().sum()\n# testfornulls","metadata":{},"execution_count":null,"outputs":[],"id":"83ea6c74-1a89-4477-9ae1-22f67f615d5f"},{"cell_type":"code","source":"#Train Test Split based on the training data\n\nXtrain_train, Xtest_train, Ytrain_train, Ytest_train = train_test_split(model_matrix_1, NoNobles_training_set,test_size=0.1, random_state=120)","metadata":{"trusted":true},"execution_count":71,"outputs":[],"id":"b2c33810-cbd3-4e39-8bf9-2d28c6078438"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"51b1e509-fe55-43de-bfe4-f7f1383e998f"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"4109f29e-9531-4e58-a696-8bf9195e520b"},{"cell_type":"code","source":"NoNobles_training_set","metadata":{"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"     material_id  dielectric_poly_total\n0      mp-555903               8.337936\n1      mp-752658              14.735277\n2        mp-3439              17.195305\n3       mp-16135              21.593507\n4       mp-36447               9.507068\n...          ...                    ...\n5609   mp-754117              13.378949\n5610  mp-1539137              16.908907\n5611  mp-1079559              11.776195\n5612   mp-555908               6.241000\n5613    mp-11653               5.887169\n\n[5614 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>material_id</th>\n      <th>dielectric_poly_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mp-555903</td>\n      <td>8.337936</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mp-752658</td>\n      <td>14.735277</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mp-3439</td>\n      <td>17.195305</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mp-16135</td>\n      <td>21.593507</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mp-36447</td>\n      <td>9.507068</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5609</th>\n      <td>mp-754117</td>\n      <td>13.378949</td>\n    </tr>\n    <tr>\n      <th>5610</th>\n      <td>mp-1539137</td>\n      <td>16.908907</td>\n    </tr>\n    <tr>\n      <th>5611</th>\n      <td>mp-1079559</td>\n      <td>11.776195</td>\n    </tr>\n    <tr>\n      <th>5612</th>\n      <td>mp-555908</td>\n      <td>6.241000</td>\n    </tr>\n    <tr>\n      <th>5613</th>\n      <td>mp-11653</td>\n      <td>5.887169</td>\n    </tr>\n  </tbody>\n</table>\n<p>5614 rows × 2 columns</p>\n</div>"},"metadata":{}}],"id":"c2b7e192-b200-45fa-8b16-5d3f64b161c4"},{"cell_type":"code","source":"#Normalizing Data\n\n# In some cases not normallizing the data provided better results. Is it always required to normalize data??\n\n# Computing mean and standard devaitaion for train X and normalizing\nmean_Xtrain = Xtrain_train.apply(np.mean, axis=0)\nstd_Xtrain = Xtrain_train.apply(np.std, axis=0)\nnorm_Xtrain = (Xtrain_train - mean_Xtrain) / std_Xtrain\n\n# Computing mean and standard devaitaion for test X and normalizing \nmean_Xtest = Xtest_train.apply(np.mean, axis=0)\nstd_Xtest = Xtest_train.apply(np.std, axis=0)\nnorm_Xtest = (Xtest_train - mean_Xtest) / std_Xtest\n\n","metadata":{"trusted":true},"execution_count":76,"outputs":[],"id":"dabcec35-9ca8-4108-8c00-de704dafaa7d"},{"cell_type":"code","source":"norm_Xtrain","metadata":{"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"             energy_per_atom  formation_energy_per_atom    nsites  nelements  \\\nmaterial_id                                                                    \nmp-556592           0.542165                   0.969454  0.251165   1.116641   \nmp-1771            -0.575925                   0.884305 -0.371410  -1.565208   \nmp-625367          -1.115317                  -1.400958 -0.682698  -0.224284   \nmp-756952           0.264535                  -1.235931 -0.293588  -0.224284   \nmp-557134          -1.537452                  -1.496231 -0.371410  -1.565208   \n...                      ...                        ...       ...        ...   \nmp-618177           1.387977                  -0.271445  0.873740  -0.224284   \nmp-867203           1.080880                   0.752715 -0.527054  -0.224284   \nmp-8716             0.489692                   0.768820 -0.527054  -0.224284   \nmp-9705            -0.773265                   0.569817 -0.215766   1.116641   \nmp-1222411          0.190893                   0.939142 -0.371410   1.116641   \n\n              density  band_gap  num_atoms  volume_per_atom  \\\nmaterial_id                                                   \nmp-556592    0.057414 -0.253538   0.404879         0.081716   \nmp-1771     -1.461758  0.190305  -0.953193         0.277737   \nmp-625367    2.351183  0.978757  -0.759183        -0.510011   \nmp-756952   -0.921832 -0.137165   0.986911        -0.687492   \nmp-557134   -1.124099  1.797280  -0.953193         0.232903   \n...               ...       ...        ...              ...   \nmp-618177   -1.128880  1.166398  -0.177152         1.425419   \nmp-867203    0.415445 -0.844306  -0.565172         0.224725   \nmp-8716     -0.641848 -0.839495  -0.565172         0.297104   \nmp-9705      0.157940 -0.001005   1.180921        -0.558929   \nmp-1222411  -0.586061 -0.859221  -0.371162        -0.311436   \n\n             average_Atomic mass  average_Atomic no  ...  max_Poissons ratio  \\\nmaterial_id                                          ...                       \nmp-556592               0.531357           0.551341  ...            2.817177   \nmp-1771                -1.129900          -1.153901  ...           -0.764634   \nmp-625367               0.054097          -0.008191  ...           -0.764634   \nmp-756952              -1.042118          -1.096513  ...           -0.764634   \nmp-557134              -0.978327          -0.967390  ...           -0.764634   \n...                          ...                ...  ...                 ...   \nmp-618177              -0.308273          -0.213734  ...           -0.764634   \nmp-867203               1.200858           1.270740  ...           -0.632826   \nmp-8716                 0.254911           0.327528  ...            0.057175   \nmp-9705                -0.036193          -0.099544  ...           -0.764634   \nmp-1222411             -0.663485          -0.621013  ...            0.287175   \n\n             max_Thermal conductivity  max_Van der waals radius  \\\nmaterial_id                                                       \nmp-556592                   -0.809204                 -0.678803   \nmp-1771                     -1.237252                 -1.901074   \nmp-625367                   -1.088527                 -0.279215   \nmp-756952                   -0.446085                 -0.725814   \nmp-557134                    0.159114                 -0.608288   \n...                               ...                       ...   \nmp-618177                   -0.120208                  0.919550   \nmp-867203                   -0.334356                  0.308415   \nmp-8716                     -0.306424                  0.919550   \nmp-9705                      0.066007                  0.755014   \nmp-1222411                   2.486803                 -0.114679   \n\n             max_Velocity of sound  max_Vickers hardness     max_X  \\\nmaterial_id                                                          \nmp-556592                -0.452437             -0.217012 -1.020444   \nmp-1771                  -1.344171             -0.217012  0.519943   \nmp-625367                -0.452437             -0.217012  0.519943   \nmp-756952                 0.146629             -0.217012  1.487163   \nmp-557134                -0.853131             -0.217012  0.519943   \n...                            ...                   ...       ...   \nmp-618177                -0.458489             -0.217012  0.018422   \nmp-867203                -0.452437             -0.217012 -1.736903   \nmp-8716                  -0.077001             -0.217012 -1.074178   \nmp-9705                   2.830196              4.685494 -0.196516   \nmp-1222411                0.146629             -0.217012 -0.196516   \n\n             max_Youngs modulus  max_Metallic radius  max_Electron affinity  \\\nmaterial_id                                                                   \nmp-556592             -0.445715            -0.292493               0.024903   \nmp-1771               -0.445715            -0.832968              -0.647900   \nmp-625367             -0.445715            -0.525209              -0.647900   \nmp-756952              0.590671            -0.832968               1.471089   \nmp-557134             -0.445715            -0.832968              -0.647900   \n...                         ...                  ...                    ...   \nmp-618177             -0.445715             1.243438               1.702131   \nmp-867203             -0.445715             0.613734              -1.364705   \nmp-8716                0.590671             1.243438              -0.036806   \nmp-9705               -0.445715             0.846450              -1.645288   \nmp-1222411            -0.226772             0.134611              -0.893999   \n\n             max_First Ionization Energy  \nmaterial_id                               \nmp-556592                      -1.079878  \nmp-1771                         0.588200  \nmp-625367                       0.210657  \nmp-756952                       1.778719  \nmp-557134                       0.210657  \n...                                  ...  \nmp-618177                      -0.057403  \nmp-867203                      -1.367602  \nmp-8716                        -1.382504  \nmp-9705                         0.588200  \nmp-1222411                      0.588200  \n\n[5052 rows x 68 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>energy_per_atom</th>\n      <th>formation_energy_per_atom</th>\n      <th>nsites</th>\n      <th>nelements</th>\n      <th>density</th>\n      <th>band_gap</th>\n      <th>num_atoms</th>\n      <th>volume_per_atom</th>\n      <th>average_Atomic mass</th>\n      <th>average_Atomic no</th>\n      <th>...</th>\n      <th>max_Poissons ratio</th>\n      <th>max_Thermal conductivity</th>\n      <th>max_Van der waals radius</th>\n      <th>max_Velocity of sound</th>\n      <th>max_Vickers hardness</th>\n      <th>max_X</th>\n      <th>max_Youngs modulus</th>\n      <th>max_Metallic radius</th>\n      <th>max_Electron affinity</th>\n      <th>max_First Ionization Energy</th>\n    </tr>\n    <tr>\n      <th>material_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mp-556592</th>\n      <td>0.542165</td>\n      <td>0.969454</td>\n      <td>0.251165</td>\n      <td>1.116641</td>\n      <td>0.057414</td>\n      <td>-0.253538</td>\n      <td>0.404879</td>\n      <td>0.081716</td>\n      <td>0.531357</td>\n      <td>0.551341</td>\n      <td>...</td>\n      <td>2.817177</td>\n      <td>-0.809204</td>\n      <td>-0.678803</td>\n      <td>-0.452437</td>\n      <td>-0.217012</td>\n      <td>-1.020444</td>\n      <td>-0.445715</td>\n      <td>-0.292493</td>\n      <td>0.024903</td>\n      <td>-1.079878</td>\n    </tr>\n    <tr>\n      <th>mp-1771</th>\n      <td>-0.575925</td>\n      <td>0.884305</td>\n      <td>-0.371410</td>\n      <td>-1.565208</td>\n      <td>-1.461758</td>\n      <td>0.190305</td>\n      <td>-0.953193</td>\n      <td>0.277737</td>\n      <td>-1.129900</td>\n      <td>-1.153901</td>\n      <td>...</td>\n      <td>-0.764634</td>\n      <td>-1.237252</td>\n      <td>-1.901074</td>\n      <td>-1.344171</td>\n      <td>-0.217012</td>\n      <td>0.519943</td>\n      <td>-0.445715</td>\n      <td>-0.832968</td>\n      <td>-0.647900</td>\n      <td>0.588200</td>\n    </tr>\n    <tr>\n      <th>mp-625367</th>\n      <td>-1.115317</td>\n      <td>-1.400958</td>\n      <td>-0.682698</td>\n      <td>-0.224284</td>\n      <td>2.351183</td>\n      <td>0.978757</td>\n      <td>-0.759183</td>\n      <td>-0.510011</td>\n      <td>0.054097</td>\n      <td>-0.008191</td>\n      <td>...</td>\n      <td>-0.764634</td>\n      <td>-1.088527</td>\n      <td>-0.279215</td>\n      <td>-0.452437</td>\n      <td>-0.217012</td>\n      <td>0.519943</td>\n      <td>-0.445715</td>\n      <td>-0.525209</td>\n      <td>-0.647900</td>\n      <td>0.210657</td>\n    </tr>\n    <tr>\n      <th>mp-756952</th>\n      <td>0.264535</td>\n      <td>-1.235931</td>\n      <td>-0.293588</td>\n      <td>-0.224284</td>\n      <td>-0.921832</td>\n      <td>-0.137165</td>\n      <td>0.986911</td>\n      <td>-0.687492</td>\n      <td>-1.042118</td>\n      <td>-1.096513</td>\n      <td>...</td>\n      <td>-0.764634</td>\n      <td>-0.446085</td>\n      <td>-0.725814</td>\n      <td>0.146629</td>\n      <td>-0.217012</td>\n      <td>1.487163</td>\n      <td>0.590671</td>\n      <td>-0.832968</td>\n      <td>1.471089</td>\n      <td>1.778719</td>\n    </tr>\n    <tr>\n      <th>mp-557134</th>\n      <td>-1.537452</td>\n      <td>-1.496231</td>\n      <td>-0.371410</td>\n      <td>-1.565208</td>\n      <td>-1.124099</td>\n      <td>1.797280</td>\n      <td>-0.953193</td>\n      <td>0.232903</td>\n      <td>-0.978327</td>\n      <td>-0.967390</td>\n      <td>...</td>\n      <td>-0.764634</td>\n      <td>0.159114</td>\n      <td>-0.608288</td>\n      <td>-0.853131</td>\n      <td>-0.217012</td>\n      <td>0.519943</td>\n      <td>-0.445715</td>\n      <td>-0.832968</td>\n      <td>-0.647900</td>\n      <td>0.210657</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>mp-618177</th>\n      <td>1.387977</td>\n      <td>-0.271445</td>\n      <td>0.873740</td>\n      <td>-0.224284</td>\n      <td>-1.128880</td>\n      <td>1.166398</td>\n      <td>-0.177152</td>\n      <td>1.425419</td>\n      <td>-0.308273</td>\n      <td>-0.213734</td>\n      <td>...</td>\n      <td>-0.764634</td>\n      <td>-0.120208</td>\n      <td>0.919550</td>\n      <td>-0.458489</td>\n      <td>-0.217012</td>\n      <td>0.018422</td>\n      <td>-0.445715</td>\n      <td>1.243438</td>\n      <td>1.702131</td>\n      <td>-0.057403</td>\n    </tr>\n    <tr>\n      <th>mp-867203</th>\n      <td>1.080880</td>\n      <td>0.752715</td>\n      <td>-0.527054</td>\n      <td>-0.224284</td>\n      <td>0.415445</td>\n      <td>-0.844306</td>\n      <td>-0.565172</td>\n      <td>0.224725</td>\n      <td>1.200858</td>\n      <td>1.270740</td>\n      <td>...</td>\n      <td>-0.632826</td>\n      <td>-0.334356</td>\n      <td>0.308415</td>\n      <td>-0.452437</td>\n      <td>-0.217012</td>\n      <td>-1.736903</td>\n      <td>-0.445715</td>\n      <td>0.613734</td>\n      <td>-1.364705</td>\n      <td>-1.367602</td>\n    </tr>\n    <tr>\n      <th>mp-8716</th>\n      <td>0.489692</td>\n      <td>0.768820</td>\n      <td>-0.527054</td>\n      <td>-0.224284</td>\n      <td>-0.641848</td>\n      <td>-0.839495</td>\n      <td>-0.565172</td>\n      <td>0.297104</td>\n      <td>0.254911</td>\n      <td>0.327528</td>\n      <td>...</td>\n      <td>0.057175</td>\n      <td>-0.306424</td>\n      <td>0.919550</td>\n      <td>-0.077001</td>\n      <td>-0.217012</td>\n      <td>-1.074178</td>\n      <td>0.590671</td>\n      <td>1.243438</td>\n      <td>-0.036806</td>\n      <td>-1.382504</td>\n    </tr>\n    <tr>\n      <th>mp-9705</th>\n      <td>-0.773265</td>\n      <td>0.569817</td>\n      <td>-0.215766</td>\n      <td>1.116641</td>\n      <td>0.157940</td>\n      <td>-0.001005</td>\n      <td>1.180921</td>\n      <td>-0.558929</td>\n      <td>-0.036193</td>\n      <td>-0.099544</td>\n      <td>...</td>\n      <td>-0.764634</td>\n      <td>0.066007</td>\n      <td>0.755014</td>\n      <td>2.830196</td>\n      <td>4.685494</td>\n      <td>-0.196516</td>\n      <td>-0.445715</td>\n      <td>0.846450</td>\n      <td>-1.645288</td>\n      <td>0.588200</td>\n    </tr>\n    <tr>\n      <th>mp-1222411</th>\n      <td>0.190893</td>\n      <td>0.939142</td>\n      <td>-0.371410</td>\n      <td>1.116641</td>\n      <td>-0.586061</td>\n      <td>-0.859221</td>\n      <td>-0.371162</td>\n      <td>-0.311436</td>\n      <td>-0.663485</td>\n      <td>-0.621013</td>\n      <td>...</td>\n      <td>0.287175</td>\n      <td>2.486803</td>\n      <td>-0.114679</td>\n      <td>0.146629</td>\n      <td>-0.217012</td>\n      <td>-0.196516</td>\n      <td>-0.226772</td>\n      <td>0.134611</td>\n      <td>-0.893999</td>\n      <td>0.588200</td>\n    </tr>\n  </tbody>\n</table>\n<p>5052 rows × 68 columns</p>\n</div>"},"metadata":{}}],"id":"65fd3947-1130-41ff-818a-eb4cf21fbb78"},{"cell_type":"markdown","source":"Now we can do out models and provide results","metadata":{},"id":"9569bfe4-4cea-4888-8cad-c7e9a4356140"},{"cell_type":"markdown","source":"linear model 1 is on on all the features with normalized data","metadata":{},"id":"ba957b82-03bb-44f5-b370-adde3aa3db2d"},{"cell_type":"code","source":"linear_model_1 = LinearRegression()\n\nlinear_model_1.fit(norm_Xtrain, Ytrain_train['dielectric_poly_total'])\n#linear_model_1_predictions_traintest = linear_model_1.predict(norm_Xtrain)\nlinear_model_1_predictions_test = linear_model_1.predict(model_matrix_2)\n\nlinear_model_1_score = -cross_val_score(linear_model_1, norm_Xtrain, Ytrain_train['dielectric_poly_total'], cv=5, scoring='neg_mean_absolute_error')\n\n\n\nDF_linear_model_1 = pd.DataFrame(linear_model_1_predictions_test)\nlinear_model_1_list =[test, DF_linear_model_1]\n\nsubs =  pd.concat(linear_model_1_list, axis=1)\nsubmissions = subs.rename(columns={0:'dielectric_poly_total'})\nsubmissions.to_csv(\"linreg-1-attempt-1.csv\", index=False)\n","metadata":{"trusted":true},"execution_count":77,"outputs":[],"id":"8821033f-3011-462e-8365-494bace71557"},{"cell_type":"code","source":"np.mean(linear_model_1_score)","metadata":{"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"8.974077013406822"},"metadata":{}}],"id":"f33ede2f-0bc9-48a5-9766-98f30c44e507"},{"cell_type":"code","source":"model_matrix_1","metadata":{"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"             energy_per_atom  formation_energy_per_atom  nsites  nelements  \\\nmaterial_id                                                                  \nmp-1001034         -3.715648                  -0.703661      14          3   \nmp-1001780         -5.591101                  -1.699567       4          3   \nmp-1001786         -5.900228                  -2.103385       4          3   \nmp-1002124         -9.890380                  -0.298402       2          2   \nmp-1004528         -5.614998                  -3.162482      17          4   \n...                      ...                        ...     ...        ...   \nmvc-6916           -7.098949                  -2.307339      14          3   \nmvc-6928           -6.543137                  -2.192463      14          3   \nmvc-6946           -6.122609                  -1.961400       6          2   \nmvc-7040           -8.067357                  -1.999722      18          2   \nmvc-7383           -6.225146                  -1.597210      20          3   \n\n              density  band_gap  num_atoms  volume_per_atom  \\\nmaterial_id                                                   \nmp-1001034   5.030727    0.7432        7.0        53.735123   \nmp-1001780   6.400668    1.5031        4.0        19.628830   \nmp-1001786   2.687084    1.5296        4.0        17.925309   \nmp-1002124   9.868236    0.5774        2.0        16.027883   \nmp-1004528   3.068458    6.3125       17.0        19.116437   \n...               ...       ...        ...              ...   \nmvc-6916     4.200544    0.0516        7.0        22.383730   \nmvc-6928     4.119621    1.7463        7.0        24.848833   \nmvc-6946     5.131960    2.1009        3.0        32.509720   \nmvc-7040     3.840256    3.4689        9.0        46.546747   \nmvc-7383     2.941999    2.4238       10.0        31.765523   \n\n             average_Atomic mass  average_Atomic no  ...  max_Poissons ratio  \\\nmaterial_id                                          ...                       \nmp-1001034             81.397286          35.142857  ...            0.330000   \nmp-1001780             75.660750          33.000000  ...            0.340000   \nmp-1001786             29.006728          14.000000  ...            0.294269   \nmp-1002124             95.250350          39.000000  ...            0.370000   \nmp-1004528             35.324664          15.294118  ...            0.440000   \n...                          ...                ...  ...                 ...   \nmvc-6916               28.311241          13.428571  ...            0.294269   \nmvc-6928               30.823657          14.857143  ...            0.310000   \nmvc-6946               50.236267          22.000000  ...            0.360000   \nmvc-7040               53.823311          22.888889  ...            0.300000   \nmvc-7383               28.139700          13.400000  ...            0.294269   \n\n             max_Thermal conductivity  max_Van der waals radius  \\\nmaterial_id                                                       \nmp-1001034                      160.0                      1.93   \nmp-1001780                      400.0                      2.24   \nmp-1001786                       85.0                      2.15   \nmp-1002124                      140.0                      2.23   \nmp-1004528                       36.0                      3.43   \n...                               ...                       ...   \nmvc-6916                        160.0                      2.05   \nmvc-6928                        200.0                      2.31   \nmvc-6946                         67.0                      2.17   \nmvc-7040                         48.0                      2.16   \nmvc-7383                        120.0                      2.06   \n\n             max_Velocity of sound  max_Vickers hardness  max_X  \\\nmaterial_id                                                       \nmp-1001034             4602.000000           2108.307692   2.55   \nmp-1001780             3723.001515           2108.307692   2.58   \nmp-1001786             6000.000000           2108.307692   2.58   \nmp-1002124            18350.000000           2108.307692   2.55   \nmp-1004528            16200.000000          49000.000000   3.98   \n...                            ...                   ...    ...   \nmvc-6916               5150.000000           2108.307692   3.44   \nmvc-6928               4910.000000           2108.307692   3.44   \nmvc-6946               2500.000000           2108.307692   3.44   \nmvc-7040               4700.000000           2450.000000   3.44   \nmvc-7383               5940.000000           2108.307692   3.44   \n\n             max_Youngs modulus  max_Metallic radius  max_Electron affinity  \\\nmaterial_id                                                                   \nmp-1001034            45.000000             1.670000               2.020605   \nmp-1001780           130.000000             1.735000               2.077105   \nmp-1001786           111.786885             1.641000               2.077105   \nmp-1002124           111.786885             1.622591               1.262114   \nmp-1004528           111.786885             2.719000               3.401190   \n...                         ...                  ...                    ...   \nmvc-6916             198.000000             1.622591               1.461105   \nmvc-6928             211.000000             1.976000               1.461105   \nmvc-6946             111.786885             1.622591               1.461105   \nmvc-7040             463.000000             1.622591               1.461105   \nmvc-7383             279.000000             1.622591               1.461105   \n\n             max_First Ionization Energy  \nmaterial_id                               \nmp-1001034                      9.752392  \nmp-1001780                     10.360010  \nmp-1001786                     10.360010  \nmp-1002124                     11.260288  \nmp-1004528                     17.422820  \n...                                  ...  \nmvc-6916                       13.618055  \nmvc-6928                       13.618055  \nmvc-6946                       13.618055  \nmvc-7040                       13.618055  \nmvc-7383                       13.618055  \n\n[5614 rows x 68 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>energy_per_atom</th>\n      <th>formation_energy_per_atom</th>\n      <th>nsites</th>\n      <th>nelements</th>\n      <th>density</th>\n      <th>band_gap</th>\n      <th>num_atoms</th>\n      <th>volume_per_atom</th>\n      <th>average_Atomic mass</th>\n      <th>average_Atomic no</th>\n      <th>...</th>\n      <th>max_Poissons ratio</th>\n      <th>max_Thermal conductivity</th>\n      <th>max_Van der waals radius</th>\n      <th>max_Velocity of sound</th>\n      <th>max_Vickers hardness</th>\n      <th>max_X</th>\n      <th>max_Youngs modulus</th>\n      <th>max_Metallic radius</th>\n      <th>max_Electron affinity</th>\n      <th>max_First Ionization Energy</th>\n    </tr>\n    <tr>\n      <th>material_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mp-1001034</th>\n      <td>-3.715648</td>\n      <td>-0.703661</td>\n      <td>14</td>\n      <td>3</td>\n      <td>5.030727</td>\n      <td>0.7432</td>\n      <td>7.0</td>\n      <td>53.735123</td>\n      <td>81.397286</td>\n      <td>35.142857</td>\n      <td>...</td>\n      <td>0.330000</td>\n      <td>160.0</td>\n      <td>1.93</td>\n      <td>4602.000000</td>\n      <td>2108.307692</td>\n      <td>2.55</td>\n      <td>45.000000</td>\n      <td>1.670000</td>\n      <td>2.020605</td>\n      <td>9.752392</td>\n    </tr>\n    <tr>\n      <th>mp-1001780</th>\n      <td>-5.591101</td>\n      <td>-1.699567</td>\n      <td>4</td>\n      <td>3</td>\n      <td>6.400668</td>\n      <td>1.5031</td>\n      <td>4.0</td>\n      <td>19.628830</td>\n      <td>75.660750</td>\n      <td>33.000000</td>\n      <td>...</td>\n      <td>0.340000</td>\n      <td>400.0</td>\n      <td>2.24</td>\n      <td>3723.001515</td>\n      <td>2108.307692</td>\n      <td>2.58</td>\n      <td>130.000000</td>\n      <td>1.735000</td>\n      <td>2.077105</td>\n      <td>10.360010</td>\n    </tr>\n    <tr>\n      <th>mp-1001786</th>\n      <td>-5.900228</td>\n      <td>-2.103385</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2.687084</td>\n      <td>1.5296</td>\n      <td>4.0</td>\n      <td>17.925309</td>\n      <td>29.006728</td>\n      <td>14.000000</td>\n      <td>...</td>\n      <td>0.294269</td>\n      <td>85.0</td>\n      <td>2.15</td>\n      <td>6000.000000</td>\n      <td>2108.307692</td>\n      <td>2.58</td>\n      <td>111.786885</td>\n      <td>1.641000</td>\n      <td>2.077105</td>\n      <td>10.360010</td>\n    </tr>\n    <tr>\n      <th>mp-1002124</th>\n      <td>-9.890380</td>\n      <td>-0.298402</td>\n      <td>2</td>\n      <td>2</td>\n      <td>9.868236</td>\n      <td>0.5774</td>\n      <td>2.0</td>\n      <td>16.027883</td>\n      <td>95.250350</td>\n      <td>39.000000</td>\n      <td>...</td>\n      <td>0.370000</td>\n      <td>140.0</td>\n      <td>2.23</td>\n      <td>18350.000000</td>\n      <td>2108.307692</td>\n      <td>2.55</td>\n      <td>111.786885</td>\n      <td>1.622591</td>\n      <td>1.262114</td>\n      <td>11.260288</td>\n    </tr>\n    <tr>\n      <th>mp-1004528</th>\n      <td>-5.614998</td>\n      <td>-3.162482</td>\n      <td>17</td>\n      <td>4</td>\n      <td>3.068458</td>\n      <td>6.3125</td>\n      <td>17.0</td>\n      <td>19.116437</td>\n      <td>35.324664</td>\n      <td>15.294118</td>\n      <td>...</td>\n      <td>0.440000</td>\n      <td>36.0</td>\n      <td>3.43</td>\n      <td>16200.000000</td>\n      <td>49000.000000</td>\n      <td>3.98</td>\n      <td>111.786885</td>\n      <td>2.719000</td>\n      <td>3.401190</td>\n      <td>17.422820</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>mvc-6916</th>\n      <td>-7.098949</td>\n      <td>-2.307339</td>\n      <td>14</td>\n      <td>3</td>\n      <td>4.200544</td>\n      <td>0.0516</td>\n      <td>7.0</td>\n      <td>22.383730</td>\n      <td>28.311241</td>\n      <td>13.428571</td>\n      <td>...</td>\n      <td>0.294269</td>\n      <td>160.0</td>\n      <td>2.05</td>\n      <td>5150.000000</td>\n      <td>2108.307692</td>\n      <td>3.44</td>\n      <td>198.000000</td>\n      <td>1.622591</td>\n      <td>1.461105</td>\n      <td>13.618055</td>\n    </tr>\n    <tr>\n      <th>mvc-6928</th>\n      <td>-6.543137</td>\n      <td>-2.192463</td>\n      <td>14</td>\n      <td>3</td>\n      <td>4.119621</td>\n      <td>1.7463</td>\n      <td>7.0</td>\n      <td>24.848833</td>\n      <td>30.823657</td>\n      <td>14.857143</td>\n      <td>...</td>\n      <td>0.310000</td>\n      <td>200.0</td>\n      <td>2.31</td>\n      <td>4910.000000</td>\n      <td>2108.307692</td>\n      <td>3.44</td>\n      <td>211.000000</td>\n      <td>1.976000</td>\n      <td>1.461105</td>\n      <td>13.618055</td>\n    </tr>\n    <tr>\n      <th>mvc-6946</th>\n      <td>-6.122609</td>\n      <td>-1.961400</td>\n      <td>6</td>\n      <td>2</td>\n      <td>5.131960</td>\n      <td>2.1009</td>\n      <td>3.0</td>\n      <td>32.509720</td>\n      <td>50.236267</td>\n      <td>22.000000</td>\n      <td>...</td>\n      <td>0.360000</td>\n      <td>67.0</td>\n      <td>2.17</td>\n      <td>2500.000000</td>\n      <td>2108.307692</td>\n      <td>3.44</td>\n      <td>111.786885</td>\n      <td>1.622591</td>\n      <td>1.461105</td>\n      <td>13.618055</td>\n    </tr>\n    <tr>\n      <th>mvc-7040</th>\n      <td>-8.067357</td>\n      <td>-1.999722</td>\n      <td>18</td>\n      <td>2</td>\n      <td>3.840256</td>\n      <td>3.4689</td>\n      <td>9.0</td>\n      <td>46.546747</td>\n      <td>53.823311</td>\n      <td>22.888889</td>\n      <td>...</td>\n      <td>0.300000</td>\n      <td>48.0</td>\n      <td>2.16</td>\n      <td>4700.000000</td>\n      <td>2450.000000</td>\n      <td>3.44</td>\n      <td>463.000000</td>\n      <td>1.622591</td>\n      <td>1.461105</td>\n      <td>13.618055</td>\n    </tr>\n    <tr>\n      <th>mvc-7383</th>\n      <td>-6.225146</td>\n      <td>-1.597210</td>\n      <td>20</td>\n      <td>3</td>\n      <td>2.941999</td>\n      <td>2.4238</td>\n      <td>10.0</td>\n      <td>31.765523</td>\n      <td>28.139700</td>\n      <td>13.400000</td>\n      <td>...</td>\n      <td>0.294269</td>\n      <td>120.0</td>\n      <td>2.06</td>\n      <td>5940.000000</td>\n      <td>2108.307692</td>\n      <td>3.44</td>\n      <td>279.000000</td>\n      <td>1.622591</td>\n      <td>1.461105</td>\n      <td>13.618055</td>\n    </tr>\n  </tbody>\n</table>\n<p>5614 rows × 68 columns</p>\n</div>"},"metadata":{}}],"id":"85484639-66bc-47c4-9977-3bfd736c9c97"},{"cell_type":"markdown","source":"linear model 2 is on on all the features with non normalized data","metadata":{},"id":"6f142674-5e1e-4171-9f00-afca33e22bd7"},{"cell_type":"code","source":"linear_model_2 = LinearRegression()\n\nlinear_model_2.fit(Xtrain_train, Ytrain_train['dielectric_poly_total'])\nlinear_model_2_predictions_traintest = linear_model_2.predict(Xtest_train)\nlinear_model_2_predictions_test = linear_model_2.predict(model_matrix_2)\n\nlinear_model_2_score = -cross_val_score(linear_model_2, Xtrain_train, Ytrain_train['dielectric_poly_total'], cv=5, scoring='neg_mean_absolute_error')\n\n\n\nDF_linear_model_2 = pd.DataFrame(linear_model_2_predictions_test)\nlinear_model_2_list =[test, DF_linear_model_2]\n\nsubs2 =  pd.concat(linear_model_2_list, axis=1)\nsubmissions2 = subs2.rename(columns={0:'dielectric_poly_total'})\nsubmissions2.to_csv(\"linreg-2-attempt-4.csv\", index=False)\n#needed four attempts because i kept printing linearmodel1 list into subs2\n","metadata":{"trusted":true},"execution_count":89,"outputs":[],"id":"e1ff81a4-53d6-4663-b232-5236aa886aaf"},{"cell_type":"code","source":"np.mean(linear_model_2_score)","metadata":{"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"8.974077013407074"},"metadata":{}}],"id":"176a6a7e-8485-4d2f-ab60-2e4e780a820c"},{"cell_type":"markdown","source":"basically the same\n\neven though the scores are the same if you print the next two cells you will see that the number predictions are very different","metadata":{},"id":"02d04018-864f-4d73-a30f-3d22db59aa0f"},{"cell_type":"code","source":"subs","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"7c12f231-79d0-4829-be35-a1966aa15873"},{"cell_type":"markdown","source":"ridge_model_1 is with normalized data, i tried both normalized and non normalized they are equally bad","metadata":{},"id":"8b811ccb-139a-4425-b334-12042e97746f"},{"cell_type":"code","source":"ridgemodel_1 = Ridge(alpha=0.1, max_iter=-10000)\nridgemodel_1.fit(norm_Xtrain, Ytrain_train['dielectric_poly_total'])\n\nridgemodelprediction_1 = ridgemodel_1.predict(norm_Xtest)\nridgemodelprediction_1_test = ridgemodel_1.predict(model_matrix_2)\n\nridge_model_1_score = -cross_val_score(ridgemodel_1, norm_Xtrain, Ytrain_train['dielectric_poly_total'], cv=5, scoring='neg_mean_absolute_error')\n\nDF_ridge_model_1 = pd.DataFrame(ridgemodelprediction_1_test)\nridge_model_1_list = [test, DF_ridge_model_1]\n\n\n\nd_list_ridge = [test, DF_ridge_model_1]\n\n\nsubs_ridge = pd.concat(d_list_ridge, axis=1)\nsubmissions_ridge = subs_ridge.rename(columns={0:'dielectric_poly_total'})\nsubmissions_ridge.to_csv(\"ridge-1-attempt-1.csv\", index=False)","metadata":{"trusted":true},"execution_count":93,"outputs":[],"id":"f97f58b0-c81e-48be-b09c-9c08b89d778f"},{"cell_type":"code","source":"np.mean(ridge_model_1_score)","metadata":{"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"8.9740061136519"},"metadata":{}}],"id":"294a8b80-b59d-469e-9830-8b93b1a4fbe0"},{"cell_type":"code","source":"subs_ridge","metadata":{},"execution_count":null,"outputs":[],"id":"a16f473e-dd93-4a2a-9b1c-62c6eea4ecb9"},{"cell_type":"markdown","source":"not good predicted values","metadata":{},"id":"d39e1687-6884-46bf-9143-ef8c4896c118"},{"cell_type":"code","source":"# logreg = LogisticRegression(penalty='none',solver='lbfgs', max_iter=1000)\n# logregmodel_1 = logreg.fit(norm_Xtrain, Ytrain_train['dielectric_poly_total'])\n\n# logregmodel_1_score = -cross_val_score(logregmodel_1, norm_train_X, y_train['dielectric_poly_total'], cv=5, scoring='neg_mean_absolute_error')\n\n# logreg_prediction_1_test = logregmodel_1.predict(model_matrix_2)\n\n# DF_logregmodel_1 = pd.DataFrame(logreg_prediction_1_test)\n\n# d_list_logreg = [test, DF_logregmodel_1]\n\n\n# subs_logreg = pd.concat(d_list_logreg, axis=1)\n# submissions_logreg = subs_logreg.rename(columns={0:'dielectric_poly_total'})\n# submissions_logreg.to_csv(\"logreg-1-attempt-1.csv\", index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"7fc213c4-bf98-4b6f-bfbc-ca721276746d"},{"cell_type":"markdown","source":"got an error for the logreg model","metadata":{},"id":"96ff94c7-a01e-4234-8fca-60a4e6ff6d79"},{"cell_type":"markdown","source":"going to try the best model i have at this point with a major feature reduction\n","metadata":{},"id":"a7b5cddc-1bd6-4671-937d-0e545972afd4"},{"cell_type":"code","source":"droplist_5 = droplist_2 + ","metadata":{},"execution_count":null,"outputs":[],"id":"d3f4edaf-5c27-48cb-b6ef-1f654e1a8e71"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"4fd0ac9d-4d59-4f2b-bfa9-9f44daf57dbc"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"f986583d-d1cf-48ba-a641-6b3656c126bc"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"c1fa3caa-ac3d-4610-88d3-42e330e4b792"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"97e048b4-d91d-4c52-889c-90bd516cb6e8"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"993e9be2-da9b-48d4-9ad3-c64ed2cbc0db"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"05df371e-36e8-4b58-8f5c-543151145335"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"faed9b8a-6fb0-4445-b001-2854ea0cd98c"}]}